<<<<<<< HEAD
{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"LS_DS_413_Document_Classification_Assignment.ipynb","provenance":[{"file_id":"1dJt15wxHd6MmrwMblY55M5fDLsj6Hysp","timestamp":1630458235743},{"file_id":"1SQU01-IgLWP3APnCOv01u50g9hbmMTP7","timestamp":1630098675869}],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"RIaw2IDPGfBo"},"source":["Lambda School Data Science\n","\n","*Unit 4, Sprint 1, Module 3*\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"X-0cqJc8GfBq"},"source":["# Document Classification (Assignment)\n","\n","This notebook is for you to practice skills during lecture.\n","\n","Today's guided module project and assignment will be different. You already know how to do classification. You ready know how to extract features from documents. So? That means you're ready to combine and practice those skills in a [kaggle competition](https://www.kaggle.com/c/whiskey-201911/) We we will open with a five minute sprint explaining the competition, and then give you 25 minutes to work. After those twenty five minutes are up, I will give a 5-minute demo an NLP technique that will help you with document classification (*and **maybe** the competition*).\n","\n","Today's all about having fun and practicing your skills.\n","\n","## Sections\n","* <a href=\"#p1\">Part 1</a>: Text Feature Extraction & Classification Pipelines\n","* <a href=\"#p2\">Part 2</a>: Latent Semantic Indexing\n","* <a href=\"#p3\">Part 3</a>: Word Embeddings with Spacy\n","* <a href=\"#p4\">Part 4</a>: Post Lecture Assignment"]},{"cell_type":"markdown","metadata":{"id":"I7YZNjEbGfBr"},"source":["# Text Feature Extraction & Classification Pipelines (Learn)\n","<a id=\"p1\"></a>"]},{"cell_type":"markdown","metadata":{"id":"tfAUasgKoKVc"},"source":["We are going to run increasingly sophisticated classification models on our whisky reviews in parts 1, 2, and 3. For each of parts 1, 2, and 3, submit your best model's results to the Kaggle competition to measure `generalization accuracy` -- i.e. how well the model performs on new data."]},{"cell_type":"markdown","metadata":{"id":"-v3SlXgD5Tk9"},"source":["##1. Classifier based on TfIdf vectorization of reviews"]},{"cell_type":"markdown","metadata":{"toc-hr-collapsed":true,"id":"DpfX8zyJGfBs"},"source":["### Follow Along \n","\n","1. Join the Kaggle Competition\n","2. Download the data\n","3. Train and hyperparameter tune a model using an sklearn pipeline"]},{"cell_type":"markdown","metadata":{"id":"iUrJ2rARmfkE"},"source":["### 1.0 Setup"]},{"cell_type":"markdown","metadata":{"id":"PWCleLr4lyP7"},"source":["#### 1.0.1 Get spacy and restart runtime"]},{"cell_type":"code","metadata":{"id":"ysPkqrmcl2I8"},"source":["#YOUR CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RNImGQB1l56U"},"source":["#### 1.0.2 import necessary packages, load spacy"]},{"cell_type":"code","metadata":{"id":"l4KcM3TcMO-N"},"source":["import pandas as pd\n","import re\n","\n","from sklearn.model_selection import RandomizedSearchCV\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n","import xgboost as xgb\n","from xgboost import XGBClassifier\n","\n","from sklearn.decomposition import TruncatedSVD\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","from sklearn.pipeline import Pipeline\n","import spacy"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KsNq7a5WP_Tw"},"source":["Load `spacy`"]},{"cell_type":"code","metadata":{"id":"e1V3ApAvMDYx"},"source":["#YOUR CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UimXwG9tGfBs"},"source":["#### 1.0.3 Load Kaggle Whisky Competition Data\n","The goal is to predict the rating from the review text"]},{"cell_type":"code","metadata":{"id":"Nf-b1D-wGfBt"},"source":["# !!!!! You may need to change the path !!!!!\n","# You can download these datasets from the Kaggle in-class \n","# competition for your cohort. \n"," \n","train = pd.read_csv('train.csv')\n","test = pd.read_csv('test.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"LnMkWvxdGfBu","executionInfo":{"status":"ok","timestamp":1630095008827,"user_tz":360,"elapsed":16,"user":{"displayName":"Ryan Allred","photoUrl":"","userId":"04031804316926795705"}},"outputId":"33933d8e-efab-4908-b570-7a92c7f0964b"},"source":["train.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>description</th>\n","      <th>ratingCategory</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1321</td>\n","      <td>\\nSometimes, when whisky is batched, a few lef...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3861</td>\n","      <td>\\nAn uncommon exclusive bottling of a 6 year o...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>655</td>\n","      <td>\\nThis release is a port version of Amrut’s In...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>555</td>\n","      <td>\\nThis 41 year old single cask was aged in a s...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1965</td>\n","      <td>\\nQuite herbal on the nose, with aromas of dri...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     id                                        description  ratingCategory\n","0  1321  \\nSometimes, when whisky is batched, a few lef...               1\n","1  3861  \\nAn uncommon exclusive bottling of a 6 year o...               0\n","2   655  \\nThis release is a port version of Amrut’s In...               1\n","3   555  \\nThis 41 year old single cask was aged in a s...               1\n","4  1965  \\nQuite herbal on the nose, with aromas of dri...               1"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"9uPjYRcHMa7N"},"source":["### 1.1 Clean Text"]},{"cell_type":"code","metadata":{"id":"1YTBavgJMj3Y"},"source":["def clean_doc(text):\n","  # COMPLETE THE CODE IN THIS CELL\n","  # remove new line characters\n","  text = text.replace('\\\\n', ' ')\n","  # remove numbers from the text\n","  text = re.sub(???)\n","  # remove multiple white spaces\n","  text = re.sub(???)\n","\n","  # case normalize and strip extra white spaces on the far left and right hand side\n","  text = ???\n","  return text\n","\n","train['description'] = train['description'].apply(clean_doc)\n","test['description'] = test['description'].apply(clean_doc)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":103},"id":"LU3Dvu_7MmSQ","executionInfo":{"status":"ok","timestamp":1630095013347,"user_tz":360,"elapsed":10,"user":{"displayName":"Ryan Allred","photoUrl":"","userId":"04031804316926795705"}},"outputId":"5e53a3ae-00fd-4130-903d-7f472bb04d24"},"source":["train['description'][0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'sometimes when whisky is batched a few leftover barrels are returned to the warehouse canadian club recently pulled and vatted several of these from the s acetone granny smith apples and fresh cut white cedar showcase this long age complex and spicy yet reserved this dram is ripe with strawberries canned pears cloves pepper and faint flowers then slightly pulling oak tannins distinct elegant and remarkably vibrant this ancient canadian club is anything but tired australia only a'"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"zdqYMpmFMvto"},"source":["### 1.2 Split training data into Feature Matrix `X` and Target Vector `y`"]},{"cell_type":"code","metadata":{"id":"DJFIJlu3MzH7"},"source":["target = 'ratingCategory'\n","# COMPLETE THE CODE IN THIS CELL\n","y = train[...]\n","X = train[...]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5IHzPRZ2GfBv"},"source":["### 1.3 Specify the Model and Define the Pipeline Components\n","\n","For the classifier model, you can try any or several of \n","* `RandomForestClassifier()` or `GradientBoostingClassifier()` from the `sklearn` library\n","* `XGBClassifier()` from the `xgboost` library\n","* `CatboostClassifier()` from the `catboost` library\n","* `LGBMClassifier()` from the `lightgbm` library\n"]},{"cell_type":"code","metadata":{"id":"Ju6TgtdzGfBw"},"source":["# limit max_features to 500 to speed up training on Colab.\n","# COMPLETE THE CODE IN THIS CELL\n","vect = TfidfVectorizer(...)\n","clf = XGBClassifier(...)\n","\n","pipe = Pipeline([(...), (...)])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"clooAQkiGfBx"},"source":["### 1.4 Define Your Search Space\n","You're looking for both the best hyperparameters of your vectorizer and your classification model. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q3R9iNggGfBx","executionInfo":{"status":"ok","timestamp":1630095224218,"user_tz":360,"elapsed":198747,"user":{"displayName":"Ryan Allred","photoUrl":"","userId":"04031804316926795705"}},"outputId":"d5136d65-9bc5-488f-99bf-fe8de19bc22f"},"source":["# COMPLETE THE CODE IN THIS CELL\n","# Parameters to search in dictionary \n","parameters = {\n","    'vect__max_df': (...),\n","    'clf__max_depth':(...)\n","}\n","\n","# Implement a grid search with cross-validation\n","grid_search = GridSearchCV(...)\n","grid_search.fit(...)\n","\n","# Display the best score from the grid search\n","grid_search.???"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:  2.9min finished\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["0.729631700536772"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bGd5eDV6PC3X","executionInfo":{"status":"ok","timestamp":1630095224219,"user_tz":360,"elapsed":30,"user":{"displayName":"Ryan Allred","photoUrl":"","userId":"04031804316926795705"}},"outputId":"13c20cf0-54e3-4125-9715-b406117e3781"},"source":["# Display the best parameters from the grid search\n","print(grid_search.best_params_)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'clf__max_depth': 20, 'vect__max_df': 0.75}"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"lK4r904hGfBy"},"source":["### 1.5 Make a Submission File\n","*Note:* In a typical Kaggle competition, you are only allowed two submissions a day, so only submit when your predicted test accuracy is the highest you can make it. For this competition the max daily submissions are capped at **20**.  The submission file is made from the results of running your best model on the test data set, for which we don't get the targets."]},{"cell_type":"code","metadata":{"id":"gEQo7ikVGfBy"},"source":["# COMPLETE THE CODE IN THIS CELL\n","# Predictions on **test** sample\n","pred = grid_search.predict(...)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VtE6ZpNnGfBy"},"source":["# COMPLETE THE CODE IN THIS CELL\n","submission = pd.DataFrame({... : ..., ...: ...})\n","submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"MrkTTtjoGfBz","executionInfo":{"status":"ok","timestamp":1630095224222,"user_tz":360,"elapsed":23,"user":{"displayName":"Ryan Allred","photoUrl":"","userId":"04031804316926795705"}},"outputId":"7d0d5c2f-495c-4d65-f02b-9b8ffd00ec89"},"source":["# Make Sure the Category is an Integer\n","submission.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>ratingCategory</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3461</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2604</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3341</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3764</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2306</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     id  ratingCategory\n","0  3461               1\n","1  2604               1\n","2  3341               1\n","3  3764               1\n","4  2306               1"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"hUACBAiMGfB0"},"source":["# Save your Submission File\n","# Best to Use an Integer or Timestamp for different versions of your model\n","submission_number = 0\n","\n","submission.to_csv(f'submission{submission_number}.csv', index=False)\n","submission_number += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"3N-lBN63PUa9","executionInfo":{"status":"ok","timestamp":1630095224223,"user_tz":360,"elapsed":19,"user":{"displayName":"Ryan Allred","photoUrl":"","userId":"04031804316926795705"}},"outputId":"7482108b-8b9c-4027-b854-ed45f140c8db"},"source":["# Download submission if in Google Colab\n","from google.colab import files\n","files.download(f'submission{submission_number}.csv')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_6ff1ecda-3e7b-44ed-a81f-83ad1381654f\", \"submission1.csv\", 6986)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"hpg3M7vDGfB0"},"source":["## Challenge\n","\n","You're trying to achieve a minimum of 75% Accuracy on your model."]},{"cell_type":"markdown","metadata":{"id":"7rwWt0TNGfB0"},"source":["## 2. Add Latent Semantic Indexing to your pipeline (Learn)\n","<a id=\"p2\"></a>"]},{"cell_type":"markdown","metadata":{"toc-hr-collapsed":true,"id":"PZXSsX8rGfB0"},"source":["### Follow Along\n","1. Join the Kaggle Competition\n","2. Download the data\n","3. Train a model & try: \n","    - Creating a Text Extraction & Classification Pipeline\n","    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n","    - Add some Latent Semantic Indexing (LSI) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n","4. Make a submission to Kaggle \n"]},{"cell_type":"markdown","metadata":{"id":"75X-i44lGfB0"},"source":["### 2.1 Define Pipeline Components\n","\n","Nest pipelines to perform SVD on our vectorization (LSA)"]},{"cell_type":"code","metadata":{"id":"QG_lFmOyGfB1"},"source":["# COMPLETE THE CODE IN THIS CELL\n","# Transforming our Vectorization with SVD is how LSA generates topic columns\n","svd = ...\n","\n","# vectorizer and classifier like before\n","vect = TfidfVectorizer(...)\n","clf = XGBClassifier()\n","\n","# LSA pipeline with vectorizer & truncated SVD\n","lsa = Pipeline(???)\n","\n","# combine LSA pipeline together with classifier\n","pipe = Pipeline([('lsa', lsa), ('clf', clf)])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uF7_arccGfB1"},"source":["### 2.2 Define Your grid search space and run a grid search with cross-validation\n","You're looking for both the best hyperparameters of your vectorizer and your classification model. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ANy4UkVeGfB1","executionInfo":{"status":"ok","timestamp":1630095606324,"user_tz":360,"elapsed":308225,"user":{"displayName":"Ryan Allred","photoUrl":"","userId":"04031804316926795705"}},"outputId":"8acdd38d-2d77-49b7-e31c-e605aafac48a"},"source":["# COMPLETE THE CODE IN THIS CELL\n","parameters = {\n","    'lsa__svd__n_components': [...],\n","    'lsa__vect__max_df': (...),\n","    'clf__max_depth': (...)\n","}\n","\n","grid_search = GridSearchCV(pipe,parameters, cv=3, n_jobs=-1, verbose=1)\n","grid_search.fit(..., ...)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:  4.6min finished\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["GridSearchCV(cv=3, error_score=nan,\n","             estimator=Pipeline(memory=None,\n","                                steps=[('lsa',\n","                                        Pipeline(memory=None,\n","                                                 steps=[('vect',\n","                                                         TfidfVectorizer(analyzer='word',\n","                                                                         binary=False,\n","                                                                         decode_error='strict',\n","                                                                         dtype=<class 'numpy.float64'>,\n","                                                                         encoding='utf-8',\n","                                                                         input='content',\n","                                                                         lowercase=True,\n","                                                                         max_df=1.0,\n","                                                                         max_features=500,\n","                                                                         min_df=1,\n","                                                                         ngram_range=(1,\n","                                                                                      1),\n","                                                                         norm='l2',\n","                                                                         preprocessor=None,\n","                                                                         smooth_i...\n","                                                      objective='binary:logistic',\n","                                                      random_state=0,\n","                                                      reg_alpha=0, reg_lambda=1,\n","                                                      scale_pos_weight=1,\n","                                                      seed=None, silent=None,\n","                                                      subsample=1,\n","                                                      verbosity=1))],\n","                                verbose=False),\n","             iid='deprecated', n_jobs=-1,\n","             param_grid={'clf__max_depth': (15, 20),\n","                         'lsa__svd__n_components': [50, 100],\n","                         'lsa__vect__max_df': (0.75, 1.0)},\n","             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n","             scoring=None, verbose=1)"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qAXQ0qZfRNWu","executionInfo":{"status":"ok","timestamp":1630095651008,"user_tz":360,"elapsed":303,"user":{"displayName":"Ryan Allred","photoUrl":"","userId":"04031804316926795705"}},"outputId":"7d9e537b-7e65-4e70-f141-ff4ee501c374"},"source":["grid_search.best_score_"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7337908122828017"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1oVwOkS9RPLY","executionInfo":{"status":"ok","timestamp":1630095651815,"user_tz":360,"elapsed":8,"user":{"displayName":"Ryan Allred","photoUrl":"","userId":"04031804316926795705"}},"outputId":"5d0836ff-d150-4422-c434-69514295720e"},"source":["grid_search.best_params_"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'clf__max_depth': 20, 'lsa__svd__n_components': 100, 'lsa__vect__max_df': 1.0}"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"0xZotkIEGfB2"},"source":["### 2.3 Make a Submission File"]},{"cell_type":"code","metadata":{"id":"25fSUB-7GfB2"},"source":["# Predictions on test sample\n","pred = grid_search.predict(test['description'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uAawXel0GfB2"},"source":["submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n","submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"1VxekvAdGfB2","executionInfo":{"status":"ok","timestamp":1630095656160,"user_tz":360,"elapsed":12,"user":{"displayName":"Ryan Allred","photoUrl":"","userId":"04031804316926795705"}},"outputId":"87e6b868-e27c-4a40-b940-eb4b9392e94e"},"source":["# Make Sure the Category is an Integer\n","submission.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>ratingCategory</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3461</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2604</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3341</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3764</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2306</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     id  ratingCategory\n","0  3461               1\n","1  2604               1\n","2  3341               1\n","3  3764               1\n","4  2306               1"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"mirtMVSWGfB2"},"source":["# Save your Submission File\n","# Best to Use an Integer or Timestamp for different versions of your model\n","\n","submission.to_csv(f'submission{submission_number}.csv', index=False)\n","submission_number +=1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"i1_gHQfLTu5T","executionInfo":{"status":"ok","timestamp":1630095658942,"user_tz":360,"elapsed":13,"user":{"displayName":"Ryan Allred","photoUrl":"","userId":"04031804316926795705"}},"outputId":"21bef41c-a5f2-4b10-f2cd-5fc74c2f008f"},"source":["# Download submission if in Google Colab\n","from google.colab import files\n","files.download(f'submission{submission_number}.csv')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_52cc0614-23af-4760-8327-dd9ff5209b0a\", \"submission2.csv\", 6986)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"FLtOAlokGfB3"},"source":["## Challenge\n","\n","Continue to apply Latent Semantic Indexing (LSI) to various datasets. "]},{"cell_type":"markdown","metadata":{"id":"l_6YzbjHGfB3"},"source":["# 3. Add Spacy Word Embeddings\n","<a id=\"p3\"></a>"]},{"cell_type":"markdown","metadata":{"id":"OuAIyBRPGfB4"},"source":["## Challenge\n","\n","What you should be doing now:\n","1. Join the Kaggle Competition\n","2. Download the data\n","3. Train a model & try: \n","    - Creating a Text Extraction & Classification Pipeline\n","    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n","    - Add some Latent Semantic Indexing (lsi) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n","    - Try to extract word embeddings with Spacy and use document vectors made from those word embeddings as your features for a classification model.\n","4. Make a submission to Kaggle "]},{"cell_type":"markdown","metadata":{"id":"voankIL7GfB3"},"source":["### 3.1 Process the data set with spacy"]},{"cell_type":"code","metadata":{"id":"sTE0VTyMGfB3"},"source":["# Apply to your Dataset\n","\n","from sklearn.model_selection import RandomizedSearchCV\n","from sklearn.ensemble import GradientBoostingClassifier\n","\n","from scipy.stats import randint\n","\n","param_dist = {\n","    \n","    'max_depth' : randint(3,10),\n","    'min_samples_leaf': randint(2,15)\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rxESV0tdGfB4"},"source":["# Continue Word Embedding Work Here\n","nlp = spacy.load(\"en_core_web_md\")\n","\n","def get_word_vectors(docs):\n","    # YOUR CODE HERE\n","    return \n","\n","X_train_emb = get_word_vectors(train['description'])\n","X_test_emb = get_word_vectors(test['description'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Duovxl3NUQWk","executionInfo":{"status":"ok","timestamp":1630096431845,"user_tz":360,"elapsed":7705,"user":{"displayName":"Ryan Allred","photoUrl":"","userId":"04031804316926795705"}},"outputId":"4ab14f9d-80c0-4cfe-e02a-073a38c261e3"},"source":["rfc = RandomForestClassifier(oob_score=True)\n","\n","rfc.fit(X_train_emb, y)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n","                       criterion='gini', max_depth=None, max_features='auto',\n","                       max_leaf_nodes=None, max_samples=None,\n","                       min_impurity_decrease=0.0, min_impurity_split=None,\n","                       min_samples_leaf=1, min_samples_split=2,\n","                       min_weight_fraction_leaf=0.0, n_estimators=100,\n","                       n_jobs=None, oob_score=True, random_state=None,\n","                       verbose=0, warm_start=False)"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sErmIzPmUcb4","executionInfo":{"status":"ok","timestamp":1630096454406,"user_tz":360,"elapsed":8,"user":{"displayName":"Ryan Allred","photoUrl":"","userId":"04031804316926795705"}},"outputId":"7fe144f0-cf53-409e-bbe3-33238be36f32"},"source":["# massively overfit with the Random Forest\n","print('Training Accuracy: ', rfc.score(X_train_emb, y))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Training Accuracy:  0.9997553217518963\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"E6gj2dtAsojE"},"source":["Here we use oob_score_ (out-of-bag score) as a **proxy** for the test score;<br>\n","for your submission, you will predict on the test set, as before"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"emXFzc-EUkIo","executionInfo":{"status":"ok","timestamp":1630096477427,"user_tz":360,"elapsed":292,"user":{"displayName":"Ryan Allred","photoUrl":"","userId":"04031804316926795705"}},"outputId":"3a916c27-bdaa-4358-dbfb-1e03bddfd54c"},"source":["# validation looks decent without any tuning\n","\n","rfc.oob_score_"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7230242231465622"]},"metadata":{},"execution_count":37}]},{"cell_type":"markdown","metadata":{"id":"HNUdL4rtGfB4"},"source":["### 3.2 Make a Submission File"]},{"cell_type":"code","metadata":{"id":"--t3j2Hn_reu"},"source":["# YOUR CODE HERE\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CU7Oep--uLPR"},"source":["# Post Lecture Assignment (Stretch)\n","<a id=\"p4\"></a>\n","\n","Your primary assignment this afternoon is to achieve a minimum of 80% accuracy on the Kaggle competition. <br>\n","Once you've accomplished that, do (1), and either (2) or (3): \n","\n","1. Research \"Sentiment Analysis\". Provide answers in markdown to the following questions: \n","    - What is \"Sentiment Analysis\"? \n","    - Is Document Classification different than \"Sentiment Analysis\"? Provide evidence for your response\n","    - How do people create labeled sentiment data? Are those labels really sentiment?\n","    - What are common applications of sentiment analysis?\n","\n","2. Singular Value Decomposition (SVD) is one of the most important and powerful methods in Applied Mathematics and in all of Machine Learning.  Principal Components Analysis (PCA) -- which we used in Module 2 -- is closely releated to SVD. Research SVD using the resources below. Then write a few paragraphs explaining -- in your own words -- your understanding of SVD and why it has become so important in Machine Learning. As you write, pretend that you will be presenting this summary orally as an answer to a question during a job interview.<br>\n","\n","* [Daniela Witten](https://www.danielawitten.com/), a Professor of Mathematical Statistics at the University of Washington, recently penned a highly amusing and informative [tweetstorm](https://twitter.com/WomenInStat/status/1285611042446413824) about SVD, well worth reading!<br>\n","* [Stanford University Lecture on SVD](https://www.youtube.com/watch?v=P5mlg91as1c) <br>\n","* [StatQuest Principal Components Analysis](https://www.youtube.com/watch?v=FgakZw6K1QQ)<br>\n","* [Luis Serrano Principal Components Analysis](https://www.youtube.com/watch?v=g-Hb26agBFg)<br>\n","\n","3. Research which other models can be used for text classification -- see [Multi-Class Text Classification Model Comparison and Selection](https://towardsdatascience.com/multi-class-text-classification-model-comparison-and-selection-5eb066197568)\n","  - Try a few other classical machine learning models, and compare with the gradient boosting results \n","  - Neural Networks are becoming more popular for document classification. Why is that the case? \n","  - If you have the time and interest, check out this [text classification documentation](https://developers.google.com/machine-learning/guides/text-classification/step-2-5) from Google\n","   "]},{"cell_type":"code","metadata":{"id":"q8xSIsjGtE84"},"source":[""],"execution_count":null,"outputs":[]}]}
=======
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "U4-S1-NLP-DS11",
      "language": "python",
      "name": "u4-s1-nlp-ds11"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "LS_DS_413_Document_Classification_Assignment.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ryanleeallred/DS-Unit-4-Sprint-1-NLP/blob/main/module3-document-classification/LS_DS_413_Document_Classification_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdT3bV_yynnk"
      },
      "source": [
        "BloomTech Data Science\n",
        "\n",
        "*Unit 4, Sprint 1, Module 3*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7DcSisAynnm"
      },
      "source": [
        "# Document Classification (Assignment)\n",
        "\n",
        "This notebook is for you to practice skills during lectures.\n",
        "\n",
        "Today's guided module project and assignment will be different. You already know how to do classification. You already know how to extract features from documents. So? That means you're ready to combine and practice those skills in a Kaggle competition. We will open with a five-minute sprint explaining the competition and then give you 25 minutes to work. After those twenty-five minutes are up, I will give a 5-minute demo of an NLP technique to help you with document classification (*and **maybe** the competition*).\n",
        "\n",
        "Today is all about having fun and practicing your skills.\n",
        "\n",
        "## Sections\n",
        "* <a href=\"#p1\">Part 1</a>: Text Feature Extraction & Classification Pipelines\n",
        "* <a href=\"#p2\">Part 2</a>: Latent Semantic Indexing\n",
        "* <a href=\"#p3\">Part 3</a>: Word Embeddings with Spacy\n",
        "* <a href=\"#p4\">Part 4</a>: Post Lecture Assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v88jsjeRynnn"
      },
      "source": [
        "# Text Feature Extraction & Classification Pipelines (Learn)\n",
        "<a id=\"p1\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc-hr-collapsed": true,
        "id": "QNN2ergBynno"
      },
      "source": [
        "## Follow Along \n",
        "\n",
        "What you should be doing now:\n",
        "1. Join the Kaggle Competition\n",
        "2. Download the data\n",
        "3. Train a model (try using the pipe method I just demoed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b90FDvoynno"
      },
      "source": [
        "### Load Competition Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0jHWhFjynno"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# You may need to change the path\n",
        "train = pd.read_csv('./data/train.csv')\n",
        "test = pd.read_csv('./data/test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwPYvN8Tynnp",
        "outputId": "0e1aad4f-3112-4927-a32f-4e347ed018ef"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>description</th>\n",
              "      <th>ratingCategory</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1321</td>\n",
              "      <td>\\nSometimes, when whisky is batched, a few lef...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3861</td>\n",
              "      <td>\\nAn uncommon exclusive bottling of a 6 year o...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>655</td>\n",
              "      <td>\\nThis release is a port version of Amrut’s In...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>555</td>\n",
              "      <td>\\nThis 41 year old single cask was aged in a s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1965</td>\n",
              "      <td>\\nQuite herbal on the nose, with aromas of dri...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id                                        description  ratingCategory\n",
              "0  1321  \\nSometimes, when whisky is batched, a few lef...               1\n",
              "1  3861  \\nAn uncommon exclusive bottling of a 6 year o...               0\n",
              "2   655  \\nThis release is a port version of Amrut’s In...               1\n",
              "3   555  \\nThis 41 year old single cask was aged in a s...               1\n",
              "4  1965  \\nQuite herbal on the nose, with aromas of dri...               1"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFpBtrfKynnr"
      },
      "source": [
        "### Define Pipeline Components"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvgC1g7wynns"
      },
      "source": [
        "vect = ...\n",
        "clf = ...\n",
        "\n",
        "pipe = Pipeline([('vect', vect), ('clf', clf)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgwbuHd-ynns"
      },
      "source": [
        "### Define Your Search Space\n",
        "You're looking for both the best hyperparameters of your vectorizer and your classification model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEcWhPYBynnt"
      },
      "source": [
        "parameters = {\n",
        "    'vect__max_df': (0.75, 1.0),\n",
        "    'clf__max_depth':(5,10,15,20)\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(pipe,parameters, cv=5, n_jobs=4, verbose=1)\n",
        "grid_search.fit(..., ...)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2qG92Ewynnt"
      },
      "source": [
        "### Make a Submission File\n",
        "*Note:* In a typical Kaggle competition, you are only allowed two submissions a day, so you only submit if you feel you cannot achieve higher test accuracy. For this competition, the max daily submissions are capped at **20**. Submit for each demo and for your assignment. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyGgXUP_ynnu"
      },
      "source": [
        "# Predictions on test sample\n",
        "pred = grid_search.predict(test['description'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxWPtarJynnu"
      },
      "source": [
        "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
        "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipQUEatEynnu"
      },
      "source": [
        "# Make Sure the Category is an Integer\n",
        "submission.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biyru9ZTynnv"
      },
      "source": [
        "subNumber = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyAMgFA7ynnv"
      },
      "source": [
        "# Save your Submission File\n",
        "# Best to Use an Integer or Timestamp for different versions of your model\n",
        "\n",
        "submission.to_csv(f'./data/submission{subNumber}.csv', index=False)\n",
        "subNumber += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wItHuwrJynnv"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "You're trying to achieve a minimum of 80% Accuracy on your model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72yYHOwlynnv"
      },
      "source": [
        "## Latent Semantic Indexing (Learn)\n",
        "<a id=\"p2\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc-hr-collapsed": true,
        "id": "8PLDgih8ynnv"
      },
      "source": [
        "## Follow Along\n",
        "1. Join the Kaggle Competition\n",
        "2. Download the data\n",
        "3. Train a model & try: \n",
        "    - Creating a Text Extraction & Classification Pipeline\n",
        "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
        "    - Add some Latent Semantic Indexing (LSI) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores i.e., `lsi__svd__n_components`\n",
        "4. Make a submission to Kaggle \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grhmgVvRynnw"
      },
      "source": [
        "### Define Pipeline Components"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfvhHmjJynnw"
      },
      "source": [
        "lsi = ...\n",
        "vect = ...\n",
        "clf = ...\n",
        "\n",
        "pipe = Pipeline([('lsi', lsi), ('clf', clf)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjoGQezpynnw"
      },
      "source": [
        "### Define Your Search Space\n",
        "You're looking for both the best hyperparameters of your vectorizer and your classification model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ql1JBSD-ynnw"
      },
      "source": [
        "parameters = {\n",
        "    'lsi__svd__n_components': [10,100,250],\n",
        "    'lsi__vect__max_df': (0.75, 1.0),\n",
        "    'clf__max_depth':(5,10,15,20)\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(pipe,parameters, cv=5, n_jobs=4, verbose=1)\n",
        "grid_search.fit(..., ...)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRqe2TARynnw"
      },
      "source": [
        "### Make a Submission File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyctLRoNynnx"
      },
      "source": [
        "# Predictions on test sample\n",
        "pred = grid_search.predict(test['description'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1NpGfmRynnx"
      },
      "source": [
        "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
        "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPUfsiw4ynnx"
      },
      "source": [
        "# Make Sure the Category is an Integer\n",
        "submission.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Wg0gFAZynnx"
      },
      "source": [
        "# Save your Submission File\n",
        "# Best to Use an Integer or Timestamp for different versions of your model\n",
        "\n",
        "submission.to_csv(f'./data/submission{subNumber}.csv', index=False)\n",
        "subNumber += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztKBHR7Fynnx"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "Continue to apply Latent Semantic Indexing (LSI) to various datasets. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g72I8pUFynnx"
      },
      "source": [
        "# Word Embeddings with Spacy (Learn)\n",
        "<a id=\"p3\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bH074Cmrynnx"
      },
      "source": [
        "## Follow Along"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrW0sDHUynny"
      },
      "source": [
        "# Apply to your Dataset\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "from scipy.stats import randint\n",
        "\n",
        "param_dist = {\n",
        "    \n",
        "    'max_depth' : randint(3,10),\n",
        "    'min_samples_leaf': randint(2,15)\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFukF5laynny"
      },
      "source": [
        "# Continue Word Embedding Work Here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMRIyedTynny"
      },
      "source": [
        "### Make a Submission File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFxKFNI3ynny"
      },
      "source": [
        "# Predictions on test sample\n",
        "pred = ...predict(test['description'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eP8EJiFOynnz"
      },
      "source": [
        "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
        "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCYGwKHNynnz"
      },
      "source": [
        "# Make Sure the Category is an Integer\n",
        "submission.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4inG1uVynnz"
      },
      "source": [
        "# Save your Submission File\n",
        "# Best to Use an Integer or Timestamp for different versions of your model\n",
        "\n",
        "submission.to_csv(f'./data/submission{subNumber}.csv', index=False)\n",
        "subNumber += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuGrfMlpynnz"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "What you should be doing now:\n",
        "1. Join the Kaggle Competition\n",
        "2. Download the data\n",
        "3. Train a model & try: \n",
        "    - Creating a Text Extraction & Classification Pipeline\n",
        "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
        "    - Add some Latent Semantic Indexing (LSI) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores i.e., `lsi__svd__n_components`\n",
        "    - Try to extract word embeddings with Spacy and use those embeddings as your features for a classification model.\n",
        "4. Submit to Kaggle "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rwl1YEeCynnz"
      },
      "source": [
        "# Post Lecture Assignment\n",
        "<a id=\"p4\"></a>\n",
        "\n",
        "Your primary assignment this afternoon is to achieve a minimum of 80% accuracy on the Kaggle competition. Once you have achieved 70% accuracy, please work on the following: \n",
        "\n",
        "1. Research \"Sentiment Analysis.\" Provide answers in markdown to the following questions: \n",
        "    - What is \"Sentiment Analysis?\" \n",
        "    - Is Document Classification different than \"Sentiment Analysis?\" Provide evidence for your response\n",
        "    - How do you create labeled sentiment data? Are those labels sentiment?\n",
        "    - What are common applications of sentiment analysis?\n",
        "2. Research why word embeddings worked better for the lecture notebook than for the whiskey competition.\n",
        "    - This [text classification documentation](https://developers.google.com/machine-learning/guides/text-classification/step-2-5) from Google might be of interest.\n",
        "    - Neural Networks are becoming more popular for document classification. Why is that the case?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYI_pjX7ynn0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
>>>>>>> db77d89a124468b7f27ea9828b95b8d5b82ab9dd
